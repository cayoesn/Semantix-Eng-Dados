docker cp HIST_PAINEL_COVIDBR_2020_Parte2_06jul2021.csv namenode:/home/
docker cp HIST_PAINEL_COVIDBR_2021_Parte1_06jul2021.csv namenode:/home/
docker cp HIST_PAINEL_COVIDBR_2021_Parte2_06jul2021.csv namenode:/home/
docker cp HIST_PAINEL_COVIDBR_2021_Parte1_06jul2021.csv namenode:/home/

hdfs dfs -mkdir /user/cayo/projeto-final
hdfs dfs -copyFromLocal /home/*.csv /user/cayo/projeto-final

create database projeto_final;

create table dados_covid(
regiao string,
estado string,
municipio string,
coduf int,
codmun int,
codRegiaoSaude int,
nomeRegiaoSaude string,
data date,
semanaEpi int,
populacaoTCU2019 int,
casosAcumulado int,
casosNovos int,
obitosAcumulado int,
obitosNovos int,
recuperadosnovos int,
emAcompanhamentoNovos int,
interiorMetropolitana int)
row format delimited
fields terminated by ';'
lines terminated by '\n'
stored as textfile
tblproperties("skip.header.line.count"="1")

load data inpath '/user/cayo/projeto-final' overwrite into table dados_covid;

create table dados_covid_particionada(
regiao string,
estado string,
coduf int,
codmun int,
codRegiaoSaude int,
nomeRegiaoSaude string,
data date,
semanaEpi int,
populacaoTCU2019 int,
casosAcumulado int,
casosNovos int,
obitosAcumulado int,
obitosNovos int,
recuperadosnovos int,
emAcompanhamentoNovos int,
interiorMetropolitana int)
partitioned by (municipio string)
stored as textfile;

INSERT OVERWRITE TABLE dados_covid_particionada PARTITION(municipio) SELECT regiao, 
       estado,
       municipio,
       coduf, 
       codmun,
       codregiaosaude,
       nomeregiaosaude,
       data,
       semanaepi,
       populacaotcu2019,
       casosacumulado,
       casosnovos,
       obitosacumulado,
       obitosnovos,
       recuperadosnovos,
       emacompanhamentonovos,
       interiormetropolitana
FROM dados_covid;

dados_covid = spark.read.option("sep", ";").option("header", "true").csv("hdfs:///user/cayo/projeto-final")

dados_covid.show(10)

from pyspark.sql.functions import *
from pyspark.sql.types import FloatType, IntegerType, LongType

dados_covid_view1 = dados_covid.agg(\
    sum("Recuperadosnovos").cast(LongType()).alias("Casos_recuperados"),\
    sum("emAcompanhamentoNovos").cast(LongType()).alias("Em_acompanhamento"))

dados_covid_view1.show()

dados_covid_view2 = dados_covid.agg(\
    sum("casosAcumulado").cast(LongType()).alias("Acumulado"),\
    sum("casosNovos").cast(LongType()).alias("Casos_novos"),\
    (format_number(((sum("casosAcumulado").cast(LongType()) * 100000).cast(FloatType()) / sum("populacaoTCU2019").cast(LongType())), 2)).alias("Incidencia"))

dados_covid_view2.show()

dados_covid_view3 = dados_covid.agg(\
    sum("obitosAcumulado").cast(LongType()).alias("Obitos_acumulado"),\
    sum("obitosNovos").cast(LongType()).alias("Obitos_novos"),\
    format_number(((sum("obitosAcumulado").cast(LongType()) * 100) / sum("casosAcumulado").cast(LongType())).cast(FloatType()), 2).alias("Letalidade"),\
    format_number(((sum("obitosAcumulado").cast(LongType()) * 100000) / sum("populacaoTCU2019").cast(LongType())).cast(FloatType()), 2).alias("Mortalidade"))

dados_covid_view3.show()

dados_covid_view1.write.option('header','true').csv("/user/cayo/projeto-final/data/dados_covid_view1_hive")

dados_covid_view2.write.option('header','true').option("compression", "snappy").parquet("/user/cayo/projeto-final/data/dados_covid_view2_parquet")

